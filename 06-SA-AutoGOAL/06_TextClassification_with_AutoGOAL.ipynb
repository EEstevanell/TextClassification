{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_TextClassification_with_AutoGOAL.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"76GWp3TtCltu"},"source":["## Clasificación de textos utilizando AutoML\n","\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [AutoGOAL](https://github.com/autogoal/autogoal) y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n","\n","\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- cómo modelar un problema de clasificación con AutoGOAL\n","- cómo utilizar AutoGOAL para buscar automáticamente un *pipeline* para clasificación de textos.\n","- utilizar este *pipeline* para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6.12 - 3.8\n","- tensorflow==2.3.0\n","- autogoal==0.3.2\n","- pandas==1.1.5\n","- plotly==4.13.0\n","- tqdm==4.56.0\n"]},{"cell_type":"markdown","metadata":{"id":"qs8-IuHAWhw2"},"source":["<a name=\"setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"Lxub5L7JWiIl","executionInfo":{"status":"ok","timestamp":1615816615913,"user_tz":-60,"elapsed":1566,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n","# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n","%%capture\n","!pip install autogoal[contrib]==0.2.2\n","\n","print('Done!')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"ga7lVYFMCltv","executionInfo":{"status":"error","timestamp":1615816617577,"user_tz":-60,"elapsed":3218,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}},"outputId":"572aaee5-b504-4c86-d249-6abcea3fd0b0"},"source":["# reset environment\n","#%reset -f\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","\n","# para evaluar los modelos \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","# para configurar AutoGOAL\n","from autogoal.ml import AutoML\n","from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger,\n",")\n","from autogoal.kb import List, Sentence, Tuple, CategoricalVector\n","from autogoal.contrib import find_classes\n","\n","# para guardar el modelo\n","import pickle\n","import datetime\n","\n","print('Done!')\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6ed98f9a5421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# para configurar AutoGOAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogoal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger,\n\u001b[1;32m     20\u001b[0m )\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogoal'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"zvCAcoPfntwB"},"source":["#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\r\n","\r\n","Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."]},{"cell_type":"code","metadata":{"id":"4jvtD8EWoA-p","executionInfo":{"status":"aborted","timestamp":1615816617574,"user_tz":-60,"elapsed":3206,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["# función auxiliar que evalúa los resultados de una clasificación\r\n","def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\r\n","  \"\"\"\r\n","  data: list of the text to predict\r\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\r\n","  \"\"\"\r\n","  print('==== Sumario de la clasificación ==== ')\r\n","  print(classification_report(y_true, y_pred))\r\n","\r\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\r\n","\r\n","  # graficar matriz de confusión\r\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\r\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\r\n","\r\n","  z = cm[::-1]\r\n","  x = display_labels\r\n","  y =  x[::-1].copy()\r\n","  z_text = [[str(y) for y in x] for x in z]\r\n","\r\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\r\n","\r\n","  fig_cm.update_layout(\r\n","      height=400, width=400,\r\n","      showlegend=True,\r\n","      margin={'t':150, 'l':0},\r\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\r\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\r\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\r\n","  )\r\n","  fig_cm.show()\r\n","\r\n","\r\n","  # curva roc (definido para clasificación binaria)\r\n","  fig_roc = None\r\n","  if y_score is not None:\r\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\r\n","    fig_roc = px.area(\r\n","        x=fpr, y=tpr,\r\n","        title={'text' : f'Curva ROC (AUC={auc(fpr, tpr):.4f})', 'x':0.5, 'xanchor': 'center'},\r\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\r\n","        width=400, height=400\r\n","    )\r\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\r\n","\r\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\r\n","    fig_roc.update_xaxes(constrain='domain')\r\n","    \r\n","    fig_roc.show()\r\n","\r\n","\r\n","# Custom logger\r\n","# - imprime y guarda el mejor pipeline cada vez que se encuentre una nueva solución candidad\r\n","# - imprime pipelines cuya evaluación falló\r\n","class CustomLogger(Logger):\r\n","    def __init__(self, classifier, save_model=True, check_folder=\".\"):\r\n","        self.save_model = save_model\r\n","        self.check_folder = check_folder\r\n","        self.classifier = classifier\r\n","\r\n","    def error(self, e: Exception, solution):\r\n","        if e and solution:\r\n","            with open(\"haha_errors.log\", \"a\") as fp:\r\n","                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\r\n","\r\n","    def update_best(self, new_best, new_fn, *args):\r\n","        pipecode = datetime.datetime.now(datetime.timezone.utc).strftime(\"haha--%Y-%m-%d--%H-%M-%S--{0}\".format(hex(id(new_best))))\r\n","        with open(\"haha_update_best.log\", \"a\") as fp:\r\n","            fp.write(f\"\\n{pipecode}\\nsolution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\r\n","\r\n","        if(self.save_model):\r\n","            fp = open('{1}.pickle'.format(self.check_folder,pipecode), 'wb')\r\n","            new_best.sampler_.replay().save(fp)\r\n","            pickle.Pickler(fp).dump((self.classifier.input, self.classifier.output))\r\n","            fp.close()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me0P5d8PoHFo"},"source":["### Carga de datos y análisis exploratorio\r\n","\r\n","Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\r\n","\r\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\r\n","\r\n","- leer los datos desde un fichero en una carpeta local.\r\n","\r\n","- leer los datos directamente de un URL.\r\n","\r\n","Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\r\n"]},{"cell_type":"code","metadata":{"id":"Tg6pvcsVoHZ4","executionInfo":{"status":"aborted","timestamp":1615816617575,"user_tz":-60,"elapsed":3199,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')\r\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n","#path = './sample_data/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer datos desde un URL\r\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline-Reviews/sample_data/ejemplo_review_train.csv'\r\n","\r\n","# leer los datos\r\n","data = pd.read_csv(path, sep=',')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suEnoVDuoMvZ"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "]},{"cell_type":"code","metadata":{"id":"UQG6uQTNoNIY","executionInfo":{"status":"aborted","timestamp":1615816617576,"user_tz":-60,"elapsed":3188,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\r\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\r\n","\r\n","# obtener algunas estadísticas sobre los datos\r\n","categories = sorted(data[class_col].unique(), reverse=True)\r\n","hist= Counter(data[class_col]) \r\n","print(f'Total de instancias -> {data.shape[0]}')\r\n","print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\r\n","\r\n","print(f'Categorías -> {categories}')\r\n","print(f'Comentario de ejemplo -> {data[text_col][0]}')\r\n","print(f'Categoría del comentario -> {data[class_col][0]}')\r\n","\r\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())]))\r\n","fig.show()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-_EGWESoRsA"},"source":["Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLK_nyK1oSAP","executionInfo":{"status":"ok","timestamp":1615808911621,"user_tz":-60,"elapsed":1164,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}},"outputId":"eff19991-7f2f-45ff-c657-74d50a576b1e"},"source":["# obtener conjuntos de entrenamiento (90%) y validación (10%)\r\n","seed = 0  # fijar random_state para reproducibilidad\r\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\r\n","\r\n","print('Done!')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xQB9gdvrokzJ"},"source":["### Implementación y configuración del modelo\r\n","\r\n","Con AutoGOAL podemos configurar el modelo facilmente pues solo necesitamos instanciar la clase AutomML. Lo más importante es elegir los tipos adecuados para datos de entrada y salida en nuestro modelo y la métrica de evaluación. En este caso:\r\n","\r\n","- entrada (input): MatrixDense -> una fila por instancia y una columna por variable.\r\n","\r\n","- salida (output): CategoricalVector -> el elemento *i* representa la categoría asociada a la instancia *i*.\r\n","\r\n","Ejecute la siguiente casilla prestando atención a los comentarios adicionales."]},{"cell_type":"code","metadata":{"id":"uZoQNW4PClt4","executionInfo":{"status":"ok","timestamp":1615808914065,"user_tz":-60,"elapsed":876,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["# configuraciones\n","cfg = {}\n","cfg['iterations'] = 1 # cantidad de iteraciones a realizar\n","cfg['popsize'] = 50  # tamaño de la población\n","cfg['search_timeout'] = 3600  # tiempo máximo de búsqueda en segundos\n","cfg['evaluation_timeout'] = 600  # tiempo máximo que empleará evaluando un pipeline en segundos\n","cfg['memory'] = 20  # cantidad máxima de memoria a utilizar\n","cfg['score_metric'] = f1_score  # métrica de evaluación\n","\n","classifier = AutoML(\n","    input=MatrixDense(),  # tipo datos de entrada\n","    output=CategoricalVector(),  # tipo datos de salida\n","    \n","    score_metric=cfg['score_metric'],\n","    search_algorithm=PESearch,  # algoritmo de búsqueda\n","    registry=None,  # para incluir clases adicionales\n","    \n","    search_kwargs=dict(\n","        pop_size=cfg['popsize'],\n","        search_timeout=cfg['search_timeout'],\n","        evaluation_timeout=cfg['evaluation_timeout'],\n","        memory_limit=args.memory * 1024 ** 3,\n","    ), \n","    search_iterations=cfg['iterations'],\n","    \n","    include_filter=\".*\",  # indica qué módulos pueden incluirse en los pipelines evaluados\n","    exclude_filter=None,  # indica módulos a excluir de los pipelines evaluados\n","    \n","    validation_split=0.3,  # porción de los datos que se tomarán para evualuar el pipeline\n","    cross_validation_steps=3,  # cantidad de particiones en la crossvalidación\n","    cross_validation=\"mean\",  # tipo de agregación para los valores de la métrica en cada partición de la crossvalidación (promedio, mediana, etc.)\n","    \n","    random_state=None,  # semilla para el generador de números aleatorios\n","    errors=\"warn\",  # tratamiento ante errores\n","    metalearning_log=False,  # logs adicionales de la librería AutoGOAL\n",")\n","\n","\n","print('Done!')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNb1SPTMClt7","executionInfo":{"status":"ok","timestamp":1615803341502,"user_tz":-60,"elapsed":509,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}}},"source":["class CustomLogger(Logger):\n","    def error(self, e: Exception, solution):\n","        if e and solution:\n","            with open(\"haha_errors.log\", \"a\") as fp:\n","                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\n","\n","    def update_best(self, new_best, new_fn, *args):\n","        with open(\"haha.log\", \"a\") as fp:\n","            fp.write(f\"solution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\n","\n","# Basic logging configuration.\n","\n","logger = MemoryLogger()\n","loggers = [ProgressLogger(), ConsoleLogger(), logger]\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4nlsy-9IClt-","executionInfo":{"status":"ok","timestamp":1615803486253,"user_tz":-60,"elapsed":1146,"user":{"displayName":"JOSE IGNACIO ABREU SALAS","photoUrl":"","userId":"06657112918169434086"}},"outputId":"7bc10ea4-6e92-43b9-f457-e4c859b74283"},"source":["X_train, y_train, X_test, y_test = haha.load(max_examples=examples)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 1.60M/1.60M [00:00<00:00, 17.1MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hLbBgFnZ93up","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45d6e2b7-04a0-4dfa-fbae-cae0895faea9"},"source":["classifier.fit(X_train, y_train, logger=loggers)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n","  defaults = yaml.load(f)\n","/usr/local/lib/python3.7/dist-packages/distributed/bokeh/core.py:57: UserWarning: \n","Failed to start diagnostics server on port 8787. [Errno 99] Cannot assign requested address\n","  warnings.warn('\\n' + msg)\n","/usr/local/lib/python3.7/dist-packages/distributed/deploy/local.py:197: UserWarning: \n","Could not launch service 'bokeh' on port 8787. Got the following message:\n","\n","[Errno 99] Cannot assign requested address\n","  self.scheduler.start(scheduler_address)\n"],"name":"stderr"},{"output_type":"stream","text":["Sentence()\n","List(Word())\n","Word()\n","Tuple(List(Word()), List(Flags()))\n","Flags()\n","List(Postag())\n","Postag()\n","MatrixContinuousDense()\n","List(Stem())\n","Stem()\n","List(ContinuousVector())\n","ContinuousVector()\n","List(ContinuousVector())\n","ContinuousVector()\n","List(Flags())\n","Flags()\n","List(Flags())\n","Flags()\n","List(Summary())\n","Summary()\n","List(Summary())\n","Summary()\n","List(Flags())\n","Flags()\n","MatrixContinuousDense()\n","MatrixContinuousSparse()\n","MatrixContinuousSparse()\n","DiscreteVector()\n","MatrixContinuousDense()\n","ContinuousVector()\n","MatrixContinuousDense()\n","MatrixContinuousSparse()\n","Flags()\n","List(List(Sentence()))\n","List(Sentence())\n","Sentence()\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(Tensor3())\n","Tensor3()\n","List(List(List(Word())))\n","List(List(Word()))\n","List(Word())\n","Word()\n","List(List(Tuple(List(Word()), List(Flags()))))\n","List(Tuple(List(Word()), List(Flags())))\n","Tuple(List(Word()), List(Flags()))\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(Flags())\n","Flags()\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(DiscreteVector())\n","DiscreteVector()\n","List(List(List(Postag())))\n","List(List(Postag()))\n","List(Postag())\n","Postag()\n","List(List(MatrixContinuousDense()))\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(List(List(Stem())))\n","List(List(Stem()))\n","List(Stem())\n","Stem()\n","List(List(List(ContinuousVector())))\n","List(List(ContinuousVector()))\n","List(ContinuousVector())\n","ContinuousVector()\n","List(List(List(ContinuousVector())))\n","List(List(ContinuousVector()))\n","List(ContinuousVector())\n","ContinuousVector()\n","List(List(List(Flags())))\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","List(List(List(Flags())))\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","List(List(List(Summary())))\n","List(List(Summary()))\n","List(Summary())\n","Summary()\n","List(List(List(Summary())))\n","List(List(Summary()))\n","List(Summary())\n","Summary()\n","List(List(List(Flags())))\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","Tensor3()\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(List(MatrixContinuousDense()))\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(List(MatrixContinuousSparse()))\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(List(DiscreteVector()))\n","List(DiscreteVector())\n","DiscreteVector()\n","List(Tensor3())\n","Tensor3()\n","List(List(MatrixContinuousSparse()))\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(List(MatrixContinuousDense()))\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(List(ContinuousVector()))\n","List(ContinuousVector())\n","ContinuousVector()\n","List(List(MatrixContinuousDense()))\n","List(MatrixContinuousDense())\n","MatrixContinuousDense()\n","List(List(MatrixContinuousSparse()))\n","List(MatrixContinuousSparse())\n","MatrixContinuousSparse()\n","List(List(Flags()))\n","List(Flags())\n","Flags()\n","Starting search: generations=1\n","\u001b[1m\u001b[37mNew generation started\u001b[0m \u001b[32mbest_fn=0.0\u001b[0m \u001b[34mgenerations=1\u001b[0m \u001b[34melapsed=0:00:00\u001b[0m \u001b[34mremaining=0:00:00\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                inner=SentenceFeatureExtractor(\n","                    tokenizer=MWETokenizer(),\n","                    feature_extractor=IPRegex(full=True),\n","                    include_text=False,\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](inner=FlagsSparseVectorizer()),\n","        SGDClassifier(\n","            loss=\"hinge\",\n","            penalty=\"elasticnet\",\n","            l1_ratio=0.001,\n","            fit_intercept=True,\n","            tol=0.001,\n","            shuffle=False,\n","            epsilon=0.900391107726322,\n","            learning_rate=\"optimal\",\n","            eta0=0.35856585600154633,\n","            power_t=-1.2439973643600495,\n","            early_stopping=True,\n","            validation_fraction=0.7317079243508899,\n","            n_iter_no_change=1,\n","            average=True,\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: 'IPRegex' object is not callable\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 222, in run_method\n","    return wrap_run(input, depth)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in wrap_run\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in <listcomp>\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 218, in wrap_run\n","    return self.inner.run(xs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in run\n","    flags = [self.feature_extractor(w) for w in tokens]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in <listcomp>\n","    flags = [self.feature_extractor(w) for w in tokens]\n","TypeError: 'IPRegex' object is not callable\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[32mBest solution: improved=0.000, previous=0.000\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(List(Word())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(List(Word()))](\n","                inner=TweetTokenizer(\n","                    preserve_case=True, reduce_len=False, strip_handles=True\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Word())), CategoricalVector()),\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(List(Word())), List(List(Flags()))](\n","                inner=WikipediaContainsWordSpanish()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](inner=ListAlgorithm[List(List(Flags())), List(Flags())](inner=FlagsMerger())),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","        ](inner=FlagsDenseVectorizer()),\n","        NearestCentroid(),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: \u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                inner=SentenceFeatureExtractor(\n","                    tokenizer=WhitespaceTokenizer(),\n","                    feature_extractor=EmailRegex(full=True),\n","                    include_text=False,\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](inner=FlagsSparseVectorizer()),\n","        OneClassSVM(\n","            kernel=\"sigmoid\",\n","            degree=5,\n","            gamma=\"scale\",\n","            coef0=0.7819249343062259,\n","            shrinking=False,\n","            cache_size=399,\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: 'EmailRegex' object is not callable\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 222, in run_method\n","    return wrap_run(input, depth)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in wrap_run\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in <listcomp>\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 218, in wrap_run\n","    return self.inner.run(xs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in run\n","    flags = [self.feature_extractor(w) for w in tokens]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in <listcomp>\n","    flags = [self.feature_extractor(w) for w in tokens]\n","TypeError: 'EmailRegex' object is not callable\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                inner=SentenceFeatureExtractor(\n","                    tokenizer=SpaceTokenizer(),\n","                    feature_extractor=PhoneRegex(full=False),\n","                    include_text=False,\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","        ](inner=FlagsDenseVectorizer()),\n","        CategoricalNB(fit_prior=False),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: 'PhoneRegex' object is not callable\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 222, in run_method\n","    return wrap_run(input, depth)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in wrap_run\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in <listcomp>\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 218, in wrap_run\n","    return self.inner.run(xs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in run\n","    flags = [self.feature_extractor(w) for w in tokens]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in <listcomp>\n","    flags = [self.feature_extractor(w) for w in tokens]\n","TypeError: 'PhoneRegex' object is not callable\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                inner=SentenceFeatureExtractor(\n","                    tokenizer=ToktokTokenizer(),\n","                    feature_extractor=MultipleFeatureExtractor(\n","                        extractors=[\n","                            WikipediaContainsWord(),\n","                            EmailRegex(full=False),\n","                            MACRegex(full=False),\n","                            UrlRegex(full=False),\n","                        ],\n","                        merger=FlagsMerger(),\n","                    ),\n","                    include_text=False,\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](inner=FlagsSparseVectorizer()),\n","        NuSVC(\n","            kernel=\"poly\",\n","            degree=1,\n","            gamma=\"auto\",\n","            coef0=0.992,\n","            shrinking=True,\n","            probability=True,\n","            cache_size=399,\n","            decision_function_shape=\"ovr\",\n","            break_ties=True,\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: 'MultipleFeatureExtractor' object is not callable\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 222, in run_method\n","    return wrap_run(input, depth)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in wrap_run\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in <listcomp>\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 218, in wrap_run\n","    return self.inner.run(xs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in run\n","    flags = [self.feature_extractor(w) for w in tokens]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in <listcomp>\n","    flags = [self.feature_extractor(w) for w in tokens]\n","TypeError: 'MultipleFeatureExtractor' object is not callable\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(List(Word())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(List(Word()))](\n","                inner=TreebankWordTokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Word())), CategoricalVector()),\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(Word(domain=general, language=english))), List(List(Flags()))\n","            ](\n","                inner=MultipleFeatureExtractor(\n","                    extractors=[IPRegex(full=True), MACRegex(full=False)],\n","                    merger=FlagsMerger(),\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](inner=ListAlgorithm[List(List(Flags())), List(Flags())](inner=FlagsMerger())),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","        ](inner=FlagsDenseVectorizer()),\n","        CategoricalNB(fit_prior=False),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: transform() got an unexpected keyword argument 'y'\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 189, in fitness_fn\n","    y_pred = pipeline.run((X_test, np.zeros_like(y_test)))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/sklearn/_manual.py\", line 82, in run\n","    return super().run(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/sklearn/_builder.py\", line 54, in run\n","    return self._eval(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/sklearn/_builder.py\", line 102, in _eval\n","    return self.transform(X)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/sklearn/_manual.py\", line 65, in transform\n","    return self.vectorizer.transform(X, y=y)\n","TypeError: transform() got an unexpected keyword argument 'y'\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                inner=SentenceFeatureExtractor(\n","                    tokenizer=SpaceTokenizer(),\n","                    feature_extractor=IPRegex(full=True),\n","                    include_text=False,\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](inner=FlagsSparseVectorizer()),\n","        DecisionTreeClassifier(\n","            min_samples_split=3,\n","            min_weight_fraction_leaf=0.0,\n","            min_impurity_decrease=0.4317307749690331,\n","            ccp_alpha=0.10960397466875149,\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n","\u001b[31m(!) Error evaluating pipeline: 'IPRegex' object is not callable\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 222, in run_method\n","    return wrap_run(input, depth)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in wrap_run\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 220, in <listcomp>\n","    return [wrap_run(x, d - 1) for x in xs]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 218, in wrap_run\n","    return self.inner.run(xs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in run\n","    flags = [self.feature_extractor(w) for w in tokens]\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 136, in <listcomp>\n","    flags = [self.feature_extractor(w) for w in tokens]\n","TypeError: 'IPRegex' object is not callable\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(List(Word())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(List(Word()))](\n","                inner=WhitespaceTokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Word())), CategoricalVector()),\n","            Tuple(List(List(ContinuousVector())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(Word(domain=general, language=spanish))),\n","                List(List(ContinuousVector())),\n","            ](inner=Word2VecEmbeddingSpanish())\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(ContinuousVector())), CategoricalVector()),\n","            Tuple(List(ContinuousVector()), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(ContinuousVector())), List(ContinuousVector())\n","            ](inner=VectorAggregator(mode=\"max\"))\n","        ),\n","        TupleWrapper[\n","            Tuple(List(ContinuousVector()), CategoricalVector()),\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","        ](inner=MatrixBuilder()),\n","        LogisticRegression(\n","            penalty=\"none\",\n","            dual=False,\n","            C=9.991,\n","            fit_intercept=True,\n","            solver=\"saga\",\n","            multi_class=\"multinomial\",\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2.73G/2.73G [06:06<00:00, 8.00MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[31m(!) Error evaluating pipeline: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 20 and the array at index 1 has size 10\n","\n","Original Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/utils/_process.py\", line 40, in _restricted_function\n","    result = self.function(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/ml/_automl.py\", line 187, in fitness_fn\n","    pipeline.run((X_train, y_train))\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 427, in run\n","    raise e from None\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_algorithm.py\", line 425, in run\n","    x = step.run(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/kb/_data.py\", line 257, in run_method\n","    elements[index] = self.inner.run(elements[index])\n","  File \"/usr/local/lib/python3.7/dist-packages/autogoal/contrib/wrappers.py\", line 62, in run\n","    return np.vstack(input)\n","  File \"<__array_function__ internals>\", line 6, in vstack\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\", line 283, in vstack\n","    return _nx.concatenate(arrs, 0)\n","  File \"<__array_function__ internals>\", line 6, in concatenate\n","ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 20 and the array at index 1 has size 10\n","\u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(List(Word())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(List(Word()))](\n","                inner=WordPunctTokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Word())), CategoricalVector()),\n","            Tuple(List(List(Summary())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(Word(domain=general, language=english))),\n","                List(List(Summary())),\n","            ](inner=WikipediaSummary())\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Summary())), CategoricalVector()),\n","            Tuple(List(List(List(Sentence()))), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(List(Document())), List(List(List(Sentence())))](\n","                inner=LineTokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(List(Sentence()))), CategoricalVector()),\n","            Tuple(List(List(List(Flags()))), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(List(Sentence()))), List(List(List(Flags())))\n","            ](\n","                inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                    inner=SentenceFeatureExtractor(\n","                        tokenizer=TreebankWordTokenizer(),\n","                        feature_extractor=MACRegex(full=False),\n","                        include_text=True,\n","                    )\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(List(Flags()))), CategoricalVector()),\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(List(List(Flags()))), List(List(Flags()))](\n","                inner=ListAlgorithm[List(List(Flags())), List(Flags())](\n","                    inner=FlagsMerger()\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](inner=ListAlgorithm[List(List(Flags())), List(Flags())](inner=FlagsMerger())),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","        ](inner=FlagsDenseVectorizer()),\n","        TupleWrapper[\n","            Tuple(MatrixContinuousDense(), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](\n","            inner=RadiusNeighborsTransformer(\n","                mode=\"connectivity\",\n","                radius=-9.995,\n","                algorithm=\"kd_tree\",\n","                leaf_size=59,\n","                p=1,\n","            )\n","        ),\n","        Birch(\n","            threshold=-4.995, branching_factor=38, n_clusters=2, compute_labels=False\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.7/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[31m(!) Error evaluating pipeline: \u001b[0m\n","\u001b[34mFitness=0.000\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[31m(!) Error evaluating pipeline: Error while generating solution: Cannot find compatible implementations for interface <class 'types.Algorithm[List(Word()), List(Word())]'>\u001b[0m\n","\u001b[1m\u001b[37mEvaluating pipeline:\u001b[0m\n","Pipeline(\n","    steps=[\n","        TupleWrapper[\n","            Tuple(List(Sentence()), CategoricalVector()),\n","            Tuple(List(List(Word())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(Sentence()), List(List(Word()))](\n","                inner=MWETokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Word())), CategoricalVector()),\n","            Tuple(List(List(Summary())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(Word(domain=general, language=spanish))),\n","                List(List(Summary())),\n","            ](inner=WikipediaSummary())\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Summary())), CategoricalVector()),\n","            Tuple(List(List(List(Sentence()))), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(List(Document())), List(List(List(Sentence())))](\n","                inner=BlanklineTokenizer()\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(List(Sentence()))), CategoricalVector()),\n","            Tuple(List(List(List(Flags()))), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[\n","                List(List(List(Sentence()))), List(List(List(Flags())))\n","            ](\n","                inner=ListAlgorithm[List(Sentence()), List(Flags())](\n","                    inner=SentenceFeatureExtractor(\n","                        tokenizer=WhitespaceTokenizer(),\n","                        feature_extractor=UrlRegex(full=False),\n","                        include_text=True,\n","                    )\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(List(Flags()))), CategoricalVector()),\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","        ](\n","            inner=ListAlgorithm[List(List(List(Flags()))), List(List(Flags()))](\n","                inner=ListAlgorithm[List(List(Flags())), List(Flags())](\n","                    inner=FlagsMerger()\n","                )\n","            )\n","        ),\n","        TupleWrapper[\n","            Tuple(List(List(Flags())), CategoricalVector()),\n","            Tuple(List(Flags()), CategoricalVector()),\n","        ](inner=ListAlgorithm[List(List(Flags())), List(Flags())](inner=FlagsMerger())),\n","        TupleWrapper[\n","            Tuple(List(Flags()), CategoricalVector()),\n","            Tuple(MatrixContinuousSparse(), CategoricalVector()),\n","        ](inner=FlagsSparseVectorizer()),\n","        SGDClassifier(\n","            loss=\"hinge\",\n","            penalty=\"elasticnet\",\n","            l1_ratio=0.001,\n","            fit_intercept=True,\n","            tol=0.001,\n","            shuffle=False,\n","            epsilon=-0.992,\n","            learning_rate=\"optimal\",\n","            eta0=0.4680415791648914,\n","            power_t=-4.995,\n","            early_stopping=False,\n","            validation_fraction=0.993,\n","            n_iter_no_change=1,\n","            average=True,\n","        ),\n","    ]\n",")\n","Restricting memory to 21474836480\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.7/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-J2Rf7dvXh7m"},"source":[""],"execution_count":null,"outputs":[]}]}