<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_TextClassification_with_AutoGOAL.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"76GWp3TtCltu"},"source":["## Clasificación de textos utilizando AutoML\n","\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [AutoGOAL](https://github.com/autogoal/autogoal) y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n","\n","\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- cómo modelar un problema de clasificación con AutoGOAL\n","- cómo utilizar AutoGOAL para buscar automáticamente un *pipeline* para clasificación de textos.\n","- utilizar este *pipeline* para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6.12 - 3.8\n","- tensorflow==2.3.0\n","- autogoal==0.3.2\n","- pandas==1.1.5\n","- plotly==4.13.0\n","- tqdm==4.56.0\n"]},{"cell_type":"markdown","metadata":{"id":"qs8-IuHAWhw2"},"source":["<a name=\"sec:setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"Lxub5L7JWiIl"},"source":["# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n","# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n","%%capture\n","!pip install autogoal[contrib]==0.3.2\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga7lVYFMCltv"},"source":["# reset environment\n","%reset -f\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","# para evaluar los modelos \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, f1_score\n","from sklearn.utils.multiclass import unique_labels\n","\n","# para configurar AutoGOAL\n","from autogoal.ml import AutoML\n","from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger)\n","from autogoal.kb import MatrixContinuous, CategoricalVector\n","from autogoal.contrib import find_classes\n","\n","# para guardar el modelo\n","import pickle\n","import datetime\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zvCAcoPfntwB"},"source":["#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\r\n","\r\n","Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."]},{"cell_type":"code","metadata":{"id":"4jvtD8EWoA-p"},"source":["# función auxiliar para realizar predicciones con el modelo\r\n","def predict_model(model, cfg, data, pref='m'):\r\n","  \"\"\"\r\n","  data: list of the text to predict\r\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\r\n","  \"\"\"\r\n","  res = {}\r\n","  scores = None\r\n","\r\n","  data_tfidf = cfg['vectorizer'].transform(data)\r\n","  data_tfidf = data_tfidf.todense()\r\n","  labels = model.predict(data_tfidf)\r\n","\r\n","  if hasattr(model, 'predict_proba'):\r\n","    scores = model.predict_proba(data_tfidf)\r\n","  \r\n","    # empaquetar scores dentro de un diccionario que contiene labels, scores clase 1, scores clase 2, .... El nombre de la clase se normaliza a lowercase\r\n","    res = {f'scores_{pref}_{cls.lower()}':score for cls, score in zip(model.classes_, [col for col in scores.T])}\r\n","\r\n","  # añadir datos relativos a la predicción\r\n","  res[f'labels_{pref}'] = cfg['label_encoder'].inverse_transform(labels)\r\n","\r\n","  # convertir a dataframe ordenando las columnas primero el label y luego los scores por clase, las clases ordenadas alfabeticamente.\r\n","  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\r\n","\r\n","  return res\r\n","\r\n","\r\n","# función auxiliar que evalúa los resultados de una clasificación\r\n","def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\r\n","  \"\"\"\r\n","  data: list of the text to predict\r\n","  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\r\n","  \"\"\"\r\n","  print('==== Sumario de la clasificación ==== ')\r\n","  print(classification_report(y_true, y_pred))\r\n","\r\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\r\n","\r\n","  # graficar matriz de confusión\r\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\r\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\r\n","\r\n","  z = cm[::-1]\r\n","  x = display_labels\r\n","  y =  x[::-1].copy()\r\n","  z_text = [[str(y) for y in x] for x in z]\r\n","\r\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\r\n","\r\n","  fig_cm.update_layout(\r\n","      height=400, width=400,\r\n","      showlegend=True,\r\n","      margin={'t':150, 'l':0},\r\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\r\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\r\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\r\n","  )\r\n","  fig_cm.show()\r\n","\r\n","\r\n","  # curva roc (definido para clasificación binaria)\r\n","  fig_roc = None\r\n","  if y_score is not None:\r\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\r\n","    fig_roc = px.area(\r\n","        x=fpr, y=tpr,\r\n","        title={'text' : f'Curva ROC (AUC={auc(fpr, tpr):.4f})', 'x':0.5, 'xanchor': 'center'},\r\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\r\n","        width=400, height=400\r\n","    )\r\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\r\n","\r\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\r\n","    fig_roc.update_xaxes(constrain='domain')\r\n","    \r\n","    fig_roc.show()\r\n","\r\n","\r\n","# custom logger\r\n","# - imprime y guarda el mejor pipeline cada vez que se encuentre una nueva solución candidad\r\n","# - imprime pipelines cuya evaluación falló\r\n","class CustomLogger(Logger):\r\n","    def __init__(self, classifier, save_model=True, check_folder=\".\"):\r\n","        self.save_model = save_model\r\n","        self.check_folder = check_folder\r\n","        self.classifier = classifier\r\n","\r\n","    def error(self, e: Exception, solution):\r\n","        if e and solution:\r\n","            with open(\"reviews_errors.log\", \"a\") as fp:\r\n","                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\r\n","\r\n","    def update_best(self, new_best, new_fn, *args):\r\n","        pipecode = datetime.datetime.now(datetime.timezone.utc).strftime(\"reviews--%Y-%m-%d--%H-%M-%S--{0}\".format(hex(id(new_best))))\r\n","        with open(\"reviews_update_best.log\", \"a\") as fp:\r\n","            fp.write(f\"\\n{pipecode}\\nsolution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\r\n","\r\n","        if(self.save_model):\r\n","            fp = open('{1}.pickle'.format(self.check_folder,pipecode), 'wb')\r\n","            new_best.sampler_.replay().save(fp)\r\n","            pickle.Pickler(fp).dump((self.classifier.input, self.classifier.output))\r\n","            fp.close()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me0P5d8PoHFo"},"source":["<a name=\"sec:load-data\"></a>\r\n","### Carga de datos y análisis exploratorio\r\n","\r\n","Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\r\n","\r\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\r\n","\r\n","- leer los datos desde un fichero en una carpeta local.\r\n","\r\n","- leer los datos directamente de un URL.\r\n","\r\n","Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\r\n"]},{"cell_type":"code","metadata":{"id":"Tg6pvcsVoHZ4"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')\r\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n","#path = './sample_data/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer datos desde un URL\r\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\r\n","\r\n","# leer los datos\r\n","data = pd.read_csv(path, sep=',')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"suEnoVDuoMvZ"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "]},{"cell_type":"code","metadata":{"id":"UQG6uQTNoNIY"},"source":["text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\r\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\r\n","\r\n","# obtener algunas estadísticas sobre los datos\r\n","categories = sorted(data[class_col].unique(), reverse=True)\r\n","hist= Counter(data[class_col]) \r\n","print(f'Total de instancias -> {data.shape[0]}')\r\n","print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\r\n","\r\n","print(f'Categorías -> {categories}')\r\n","print(f'Comentario de ejemplo -> {data[text_col][0]}')\r\n","print(f'Categoría del comentario -> {data[class_col][0]}')\r\n","\r\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())]))\r\n","fig.show()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_-_EGWESoRsA"},"source":["Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."]},{"cell_type":"code","metadata":{"id":"NLK_nyK1oSAP"},"source":["# obtener conjuntos de entrenamiento (90%) y validación (10%)\r\n","seed = 0  # fijar random_state para reproducibilidad\r\n","train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xQB9gdvrokzJ"},"source":["### Implementación y configuración del modelo\r\n","\r\n","Con AutoGOAL podemos configurar el modelo facilmente pues solo necesitamos instanciar la clase AutomML. Lo más importante es elegir los tipos adecuados para datos de entrada y salida en nuestro modelo y la métrica de evaluación. En este caso:\r\n","\r\n","- entrada (input): MatrixContinuousDense -> una fila por instancia y una columna por variable.\r\n","\r\n","- salida (output): CategoricalVector -> el elemento *i* representa la categoría asociada a la instancia *i*.\r\n","\r\n","Ejecute la siguiente casilla prestando atención a los comentarios adicionales."]},{"cell_type":"code","metadata":{"id":"uZoQNW4PClt4"},"source":["# configuraciones\n","cfg = {}\n","cfg['iterations'] = 1 # cantidad de iteraciones a realizar\n","cfg['popsize'] = 50  # tamaño de la población\n","cfg['search_timeout'] = 600  # tiempo máximo de búsqueda en segundos\n","cfg['evaluation_timeout'] = 60  # tiempo máximo que empleará evaluando un pipeline en segundos\n","cfg['memory'] = 20  # cantidad máxima de memoria a utilizar\n","cfg['score_metric'] = f1_score  # métrica de evaluación\n","\n","model = AutoML(\n","    input=MatrixContinuous(),  # tipo datos de entrada\n","    output=CategoricalVector(),  # tipo datos de salida\n","    \n","    score_metric=cfg['score_metric'],\n","    search_algorithm=PESearch,  # algoritmo de búsqueda\n","    registry=None,  # para incluir clases adicionales\n","    \n","    search_kwargs=dict(\n","        pop_size=cfg['popsize'],\n","        search_timeout=cfg['search_timeout'],\n","        evaluation_timeout=cfg['evaluation_timeout'],\n","        memory_limit=cfg['memory'] * 1024 ** 3,\n","    ), \n","    search_iterations=cfg['iterations'],\n","    \n","    include_filter=\".*\",  # indica qué módulos pueden incluirse en los pipelines evaluados\n","    exclude_filter=None,  # indica módulos a excluir de los pipelines evaluados\n","    \n","    validation_split=0.3,  # porción de los datos de entrenamiento que AutoGOAL tomará para evaluar cada pipeline\n","    cross_validation_steps=3,  # cantidad de particiones en la crossvalidación\n","    cross_validation=\"mean\",  # tipo de agregación para los valores de la métrica en cada partición de la crossvalidación (promedio, mediana, etc.)\n","    \n","    random_state=None,  # semilla para el generador de números aleatorios\n","    errors=\"warn\",  # tratamiento ante errores\n","    metalearning_log=False,  # logs adicionales de la librería AutoGOAL\n",")\n","\n","# configurar loggers\n","loggers = [ProgressLogger(), ConsoleLogger(), MemoryLogger(), CustomLogger(model, save_model=True, check_folder=\".\")]\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRRPI2CzOCOo"},"source":["<a name=\"sec:pre-proc\"></a>\r\n","### Pre-procesamiento de los datos\r\n","\r\n","Antes de entrenar, debemos pre-procesar los datos. Esto dependerá de la tarea en particular, en este caso, comprende:\r\n","\r\n","- obtener vectores tf-idf correspondientes a cada ejemplo.\r\n","\r\n","- codificar las categorías como números utilizando [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) de [scikit-learn](https://scikit-learn.org/stable/). \r\n","\r\n","**Notar que:**\r\n","\r\n","- en dependencia de su implementación del extractor o del número de clases, deberá re-implementar esta sección para codificar los datos adecuadamente.\r\n","\r\n","Ejecute la siguiente casilla prestando atención a los comentarios explicativos."]},{"cell_type":"markdown","metadata":{"id":"4yoryqRsO8ik"},"source":["#### Instanciar tf-idf vectorizer, etc."]},{"cell_type":"code","metadata":{"id":"iNb1SPTMClt7"},"source":["# instanciar TfidfVectorizer\n","cfg['vectorizer'] = TfidfVectorizer(stop_words='english', max_features=10000)\n","\n","# instanciar LabelEncoder\n","cfg['label_encoder'] = LabelEncoder()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tuOwIoYjPLC8"},"source":["#### Pre-procesamiento"]},{"cell_type":"code","metadata":{"id":"4nlsy-9IClt-"},"source":["# entrenar TfidfVectorizer\r\n","cfg['vectorizer'].fit(train[text_col].to_list())\r\n","\r\n","# guardar TfidfVectorizer entrenado para su posterior uso (codificar nuevos datos).\r\n","with open('vectorizer_reviews.pkl', 'wb') as f:\r\n","    pickle.dump(cfg['vectorizer'], f)\r\n","\r\n","# entrenar LabelEncoder\r\n","cfg['label_encoder'].fit(train[class_col])\r\n","\r\n","# guardar LabelEncoder entrenado para su posterior uso (codificar nuevos datos).\r\n","with open('label_encoder_reviews.pkl', 'wb') as f:\r\n","    pickle.dump(cfg['label_encoder'], f)\r\n","\r\n","# obtener representaciones tf-idf correspondientes\r\n","train_tfidf = cfg['vectorizer'].transform(train[text_col])\r\n","val_tfidf = cfg['vectorizer'].transform(val[text_col])\r\n","\r\n","# formatear adecuadamente dado que la salida de TfidfVectorizer es de tipo scipy.sparse.csr.csr_matrix.\r\n","# no que AutoGOAL puede procesar scipy.sparse.csr.csr_matrix al entrenar, pero no necesariamente al predecir \r\n","# por lo que se sugiere formatear siempre\r\n","train_tfidf = train_tfidf.todense() \r\n","val_tfidf = val_tfidf.todense()\r\n","\r\n","# codificar labels\r\n","train_labels = cfg['label_encoder'].transform(train[class_col])\r\n","val_labels = cfg['label_encoder'].transform(val[class_col])\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rn4Poq2R4UX"},"source":["### Entrenamiento del modelo\r\n","\r\n","Por último es necesario \"entrenar el modelo\", que en este caso significa iniciar la búsqueda.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"-J2Rf7dvXh7m"},"source":["model.fit(train_tfidf, train_labels, logger=loggers)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLh4KHHgX_bw"},"source":["Finalmente, guardamos el mejor pipeline encontrado. Notar que solo se guardará su estructura por lo que al cargarlo necesitaremos entrenarlo nuevamente."]},{"cell_type":"code","metadata":{"id":"XBnxcf0WSj4h"},"source":["with open('model_reviews.pkl', 'wb') as f:\r\n","    model.save_pipeline(f)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n_9A1ZkyfCq4"},"source":["### Evaluación del modelo\r\n","Luego de entrenado el modelo, podemos evaluar su desempeño en los conjuntos de entrenamiento y validación.\r\n","\r\n","Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."]},{"cell_type":"code","metadata":{"id":"Uh_wgiOfXOWZ"},"source":["# predecir y evaluar el modelo en el conjunto de entrenamiento\r\n","print('==== Evaluación conjunto de entrenamiento ====')\r\n","data = train\r\n","true_labels = data[class_col]\r\n","\r\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\r\n","\r\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\r\n","evaluate_model(true_labels, m_pred['labels_m'])  \r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2hZlaFL7omz"},"source":["Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."]},{"cell_type":"code","metadata":{"id":"O1vinOtO7o-h"},"source":["# predecir y evaluar el modelo en el conjunto de entrenamiento\r\n","print('==== Evaluación conjunto de entrenamiento ====')\r\n","data = val\r\n","true_labels = data[class_col]\r\n","\r\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\r\n","\r\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\r\n","evaluate_model(true_labels, m_pred['labels_m'])  \r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-jAoCZGPqCj"},"source":["## Predicción de nuevos datos\r\n","\r\n","Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el entrenamiento o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\r\n","\r\n","**Notar que**:\r\n","-  se cargará el modelo previamente entrenado y guardado, estableciendo las configuraciones pertinentes.\r\n","\r\n","- si disponemos de un modelo guardado, podremos ejecutar directamente esta parte del cuaderno. Sin embargo, será necesario al menos ejecutar previamente la sección [Instalación de librerías...](#sec:setup)\r\n"]},{"cell_type":"markdown","metadata":{"id":"-ism0f1cbbH_"},"source":["### Cargar otros elementos necesarios \r\n","\r\n","Antes de predecir nuevos datos, también es preciso cargar otros elementos necesarios como el codificador para las etiquetas, etc.\r\n","\r\n","Ejecute la siguiente casilla."]},{"cell_type":"code","metadata":{"id":"6DriOyJkbbd5"},"source":["# configuraciones\r\n","text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\r\n","class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\r\n","\r\n","cfg = {}  # diccionario para agrupar configuraciones y variables para su posterior uso\r\n","\r\n","# cargar el LabelEncoder\r\n","with open('label_encoder_reviews.pkl', 'rb') as f:\r\n","    cfg['label_encoder'] = pickle.load(f)\r\n","\r\n","# cargar TfidfVectorizer\r\n","with open('vectorizer_reviews.pkl', 'rb') as f:\r\n","    cfg['vectorizer'] = pickle.load(f)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I4Fmkq3BPyvf"},"source":["### Instanciar modelo pre-entrenado\r\n","\r\n","Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado. En el caso de AutoGOAL, hemos guardado solamente la estructura del pipeline encontrado por lo que es preciso entrenarlo nuevamente al cargarlo.\r\n","\r\n"," Ejecute la siguiente casilla para cargar el pipeline."]},{"cell_type":"code","metadata":{"id":"lcFQIegh7p-a"},"source":["# cargar mejor pipeline\r\n","model = AutoML()\r\n","with open('model_reviews.pickle', 'rb') as f:\r\n","    model.load_pipeline(f)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDtF-ZzAa6Ev"},"source":["### Leer datos de entrenamiento y pre-procesarlos\r\n","Antes de entrenar el modelo, debemos leer los datos de entrenamiento y realizar el pre-procesamiento de estos. Podemos recordar los detalles de [Pre-procesamiento de los datos](#sec:pre-proc).\r\n","\r\n","Ejecute las siguientes casillas."]},{"cell_type":"code","metadata":{"id":"F7hXySFZY2N5"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')\r\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n","#path = './sample_data/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer datos desde un URL\r\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\r\n","\r\n","# leer los datos\r\n","data = pd.read_csv(path, sep=',')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxBI1CBHcayA"},"source":["En este caso, podemos entrenar con todos los datos."]},{"cell_type":"code","metadata":{"id":"NMD8LGXLaxUo"},"source":["# obtener representaciones tf-idf correspondientes\r\n","train_tfidf = cfg['vectorizer'].transform(data[text_col])\r\n","\r\n","# formatear adecuadamente dado que la salida de TfidfVectorizer es de tipo scipy.sparse.csr.csr_matrix.\r\n","train_tfidf = train_tfidf.todense() \r\n","\r\n","# codificar labels\r\n","train_labels = cfg['label_encoder'].transform(data[class_col])\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3wkEux6ld0jP"},"source":["### Entrenar mejor pipeline"]},{"cell_type":"code","metadata":{"id":"dIjPl10Md2WI"},"source":["model.fit_pipeline(train_tfidf, train_labels)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3H4me-h3eJLh"},"source":["### Predecir nuevos datos\r\n","\r\n","Con el modelo cargado, es posible utilizarlo para analizar nuevos datos. \r\n","\r\n","Ejecute las siguientes casillas para:\r\n","\r\n","(a) categorizar un texto de muestra.\r\n","\r\n","(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."]},{"cell_type":"code","metadata":{"id":"njoBIOJ-d-yg"},"source":["# ejemplo de texto a clasificar en formato [text 1, text 2, ..., text n]\r\n","text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\r\n","        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\r\n","\r\n","# predecir los nuevos datos.\r\n","m_pred = predict_model(model, cfg, text, pref='m')\r\n","\r\n","# el nombre de los campos dependerá de pref al llamar a predic_model y las clases. Ver comentarios en la definición de la función\r\n","pred_labels = m_pred['labels_m'].values[0]\r\n","\r\n","print(f'La categoría del review es -> {pred_labels}')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"soc1PQnEeZon"},"source":["También podemos predecir nuevos datos cargados desde un fichero. \r\n","\r\n","Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."]},{"cell_type":"code","metadata":{"id":"Sz8QkhPeeTlX"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')\r\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n","#path = './sample_data/ejemplo_review_train.csv'\r\n","\r\n","# descomente la siguiente línea para leer datos desde un URL\r\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline/sample_data/ejemplo_review_test.csv'\r\n","\r\n","# leer los datos\r\n","new_data = pd.read_csv(path, sep=',')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4UTCvP3QecrH"},"source":["Ejecute la siguiente celda para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."]},{"cell_type":"code","metadata":{"id":"9VGbyGdRebLH"},"source":["# predecir los datos de prueba\r\n","m_pred = predict_model(model, cfg, new_data[text_col].to_list(), pref='m')\r\n","pred_labels = m_pred['labels_m']\r\n","\r\n","# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\r\n","categories = sorted(pred_labels.unique(), reverse=True)\r\n","hist = Counter(pred_labels.values) \r\n","\r\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())]))\r\n","fig.show()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfWPYGwyefkH"},"source":[""],"execution_count":null,"outputs":[]}]}
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_TextClassification_with_AutoGOAL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/06-SA-AutoGOAL/06_TextClassification_with_AutoGOAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76GWp3TtCltu"
      },
      "source": [
        "## Clasificación de textos utilizando AutoML\n",
        "\n",
        "\n",
        "La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n",
        "\n",
        "- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n",
        "- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n",
        "\n",
        "En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [AutoGOAL](https://github.com/autogoal/autogoal) y su aplicación para clasificar reviews de [IMDB](https://www.imdb.com/) sobre películas en las categorías \\[$positive$, $negative$\\]. \n",
        "\n",
        "\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- siga las indicaciones y comentarios en cada apartado.\n",
        "\n",
        "\n",
        "**Después de esta actividad nos habremos familiarizado con:**\n",
        "- cómo modelar un problema de clasificación con AutoGOAL\n",
        "- cómo utilizar AutoGOAL para buscar automáticamente un *pipeline* para clasificación de textos.\n",
        "- utilizar este *pipeline* para clasificar nuevos textos.\n",
        "\n",
        "**Requerimientos**\n",
        "- python 3.6.12 - 3.8\n",
        "- tensorflow==2.3.0\n",
        "- autogoal==0.3.2\n",
        "- pandas==1.1.5\n",
        "- plotly==4.13.0\n",
        "- tqdm==4.56.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs8-IuHAWhw2"
      },
      "source": [
        "<a name=\"setup\"></a>\n",
        "### Instalación de librerías e importación de dependencias.\n",
        "\n",
        "Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxub5L7JWiIl"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "%%capture\n",
        "!pip install autogoal[contrib]==0.3.2\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga7lVYFMCltv",
        "outputId": "41591ae5-e7c6-4bd4-db57-7234660c7636"
      },
      "source": [
        "# reset environment\n",
        "#%reset -f\n",
        "\n",
        "#  para construir gráficas y realizar análisis exploratorio de los datos\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "\n",
        "# para cargar datos y realizar pre-procesamiento básico\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# para evaluar los modelos \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# para configurar AutoGOAL\n",
        "from autogoal.ml import AutoML\n",
        "from autogoal.search import (Logger, PESearch, ConsoleLogger, ProgressLogger, MemoryLogger,\n",
        ")\n",
        "from autogoal.kb import MatrixContinuousDense, CategoricalVector\n",
        "from autogoal.contrib import find_classes\n",
        "\n",
        "# para guardar el modelo\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "print('Done!')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvCAcoPfntwB"
      },
      "source": [
        "#### Definición de funciones y variables necesarias para el pre-procesamiento de datos\r\n",
        "\r\n",
        "Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jvtD8EWoA-p",
        "outputId": "62828346-f4ea-4b1c-d094-4bea8c4914c6"
      },
      "source": [
        "# función auxiliar que evalúa los resultados de una clasificación\r\n",
        "def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\r\n",
        "  \"\"\"\r\n",
        "  data: list of the text to predict\r\n",
        "  pref: identificador para las columnas (labels_[pref], scores_[pref]_[class 1], etc.)\r\n",
        "  \"\"\"\r\n",
        "  print('==== Sumario de la clasificación ==== ')\r\n",
        "  print(classification_report(y_true, y_pred))\r\n",
        "\r\n",
        "  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\r\n",
        "\r\n",
        "  # graficar matriz de confusión\r\n",
        "  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\r\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\r\n",
        "\r\n",
        "  z = cm[::-1]\r\n",
        "  x = display_labels\r\n",
        "  y =  x[::-1].copy()\r\n",
        "  z_text = [[str(y) for y in x] for x in z]\r\n",
        "\r\n",
        "  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\r\n",
        "\r\n",
        "  fig_cm.update_layout(\r\n",
        "      height=400, width=400,\r\n",
        "      showlegend=True,\r\n",
        "      margin={'t':150, 'l':0},\r\n",
        "      title={'text' : 'Matriz de Confusión', 'x':0.5, 'xanchor': 'center'},\r\n",
        "      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\r\n",
        "      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\r\n",
        "  )\r\n",
        "  fig_cm.show()\r\n",
        "\r\n",
        "\r\n",
        "  # curva roc (definido para clasificación binaria)\r\n",
        "  fig_roc = None\r\n",
        "  if y_score is not None:\r\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\r\n",
        "    fig_roc = px.area(\r\n",
        "        x=fpr, y=tpr,\r\n",
        "        title={'text' : f'Curva ROC (AUC={auc(fpr, tpr):.4f})', 'x':0.5, 'xanchor': 'center'},\r\n",
        "        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\r\n",
        "        width=400, height=400\r\n",
        "    )\r\n",
        "    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\r\n",
        "\r\n",
        "    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\r\n",
        "    fig_roc.update_xaxes(constrain='domain')\r\n",
        "    \r\n",
        "    fig_roc.show()\r\n",
        "\r\n",
        "\r\n",
        "# Custom logger\r\n",
        "# - imprime y guarda el mejor pipeline cada vez que se encuentre una nueva solución candidad\r\n",
        "# - imprime pipelines cuya evaluación falló\r\n",
        "class CustomLogger(Logger):\r\n",
        "    def __init__(self, classifier, save_model=True, check_folder=\".\"):\r\n",
        "        self.save_model = save_model\r\n",
        "        self.check_folder = check_folder\r\n",
        "        self.classifier = classifier\r\n",
        "\r\n",
        "    def error(self, e: Exception, solution):\r\n",
        "        if e and solution:\r\n",
        "            with open(\"reviews_errors.log\", \"a\") as fp:\r\n",
        "                fp.write(f\"solution={repr(solution)}\\nerror={repr(e)}\\n\\n\")\r\n",
        "\r\n",
        "    def update_best(self, new_best, new_fn, *args):\r\n",
        "        pipecode = datetime.datetime.now(datetime.timezone.utc).strftime(\"reviews--%Y-%m-%d--%H-%M-%S--{0}\".format(hex(id(new_best))))\r\n",
        "        with open(\"reviews_update_best.log\", \"a\") as fp:\r\n",
        "            fp.write(f\"\\n{pipecode}\\nsolution={repr(new_best)}\\nfitness={new_fn}\\n\\n\")\r\n",
        "\r\n",
        "        if(self.save_model):\r\n",
        "            fp = open('{1}.pickle'.format(self.check_folder,pipecode), 'wb')\r\n",
        "            new_best.sampler_.replay().save(fp)\r\n",
        "            pickle.Pickler(fp).dump((self.classifier.input, self.classifier.output))\r\n",
        "            fp.close()\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0P5d8PoHFo"
      },
      "source": [
        "### Carga de datos y análisis exploratorio\r\n",
        "\r\n",
        "Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\r\n",
        "\r\n",
        "- montar nuestra partición de Google Drive y leer un fichero desde esta.\r\n",
        "\r\n",
        "- leer los datos desde un fichero en una carpeta local.\r\n",
        "\r\n",
        "- leer los datos directamente de un URL.\r\n",
        "\r\n",
        "Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6pvcsVoHZ4",
        "outputId": "3bc1fcfb-0ef5-48de-94b7-c5381275065d"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive, asumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n",
        "#from google.colab import drive\r\n",
        "#drive.mount('/content/drive')\r\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n",
        "\r\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n",
        "#path = './sample_data/ejemplo_review_train.csv'\r\n",
        "\r\n",
        "# descomente la siguiente línea para leer datos desde un URL\r\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/06-SA-AutoGOAL/sample_data/ejemplo_review_train.csv'\r\n",
        "\r\n",
        "# leer los datos\r\n",
        "data = pd.read_csv(path, sep=',')\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIXXVH9wkoxj"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suEnoVDuoMvZ"
      },
      "source": [
        "Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "UQG6uQTNoNIY",
        "outputId": "a6eeebbb-5ed4-46a1-c5d0-583d333d19f5"
      },
      "source": [
        "text_col = 'Phrase'  # columna del dataframe que contiene el texto (depende del formato de los datos)\r\n",
        "class_col = 'Sentiment'  # columna del dataframe que contiene la clase (depende del formato de los datos)\r\n",
        "\r\n",
        "# obtener algunas estadísticas sobre los datos\r\n",
        "categories = sorted(data[class_col].unique(), reverse=True)\r\n",
        "hist= Counter(data[class_col]) \r\n",
        "print(f'Total de instancias -> {data.shape[0]}')\r\n",
        "print(f'Distribución de clases -> {{item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}}')\r\n",
        "\r\n",
        "print(f'Categorías -> {categories}')\r\n",
        "print(f'Comentario de ejemplo -> {data[text_col][0]}')\r\n",
        "print(f'Categoría del comentario -> {data[class_col][0]}')\r\n",
        "\r\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())]))\r\n",
        "fig.show()\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de instancias -> 1763\n",
            "Distribución de clases -> {item[0]:round(item[1]/len(data[class_col]), 3) for item in sorted(hist.items(), key=lambda x: x[0])}\n",
            "Categorías -> ['positive', 'negative']\n",
            "Comentario de ejemplo -> This is a great movie that everyone should see. It plays like a Dean Koontz book.<br /><br />Bill Paxton's performance was great in that it really seems like he believes in what he is saying and doing.<br /><br />I don't know why viewers have to read in some kind of advocacy for religious murder in to the film. It is fiction. The ending is surprising, but fictional. So what? I think that is what makes this movie so good. SPOILER DO NOT READ FURTHER IF YOU HAVENT SEEN THE MOVIE. Throughout the movie, the viewer is continually shocked at the sickness of Paxton's character, the impact on the children, and the way the children handle this outrageous conduct. And then at the end, it turns out to be true. God has put him on a mission to rid the world of demons. Paxton is not clairvoyant as other viewers suggest. Sure, he is given info that he couldn't have known otherwise, but the movie goes further to show how God is \"protecting\" Adam through the convenient video quality problem and the complete lack of memory of the second FBI agent. The film isn't advocating Christian murder, it is merely taking the viewer on a very unexpected ride.\n",
            "Categoría del comentario -> positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"33e6427e-4966-4a0b-8a5f-a532d63bda58\" class=\"plotly-graph-div\" style=\"height:400px; width:600px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"33e6427e-4966-4a0b-8a5f-a532d63bda58\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '33e6427e-4966-4a0b-8a5f-a532d63bda58',\n",
              "                        [{\"type\": \"bar\", \"x\": [\"positive\", \"negative\"], \"y\": [901, 862]}],\n",
              "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 600},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('33e6427e-4966-4a0b-8a5f-a532d63bda58');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-_EGWESoRsA"
      },
      "source": [
        "Finalmente, ejecute la siguiente casilla para crear los conjuntos de entrenamiento y validación que se utilizarán para entrenar y validar los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLK_nyK1oSAP",
        "outputId": "ad606594-f986-480e-8655-0c5ac99f35dd"
      },
      "source": [
        "# obtener conjuntos de entrenamiento (90%) y validación (10%)\r\n",
        "seed = 0  # fijar random_state para reproducibilidad\r\n",
        "train, val = train_test_split(data, test_size=.1, stratify=data[class_col], random_state=seed)\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQB9gdvrokzJ"
      },
      "source": [
        "### Implementación y configuración del modelo\r\n",
        "\r\n",
        "Con AutoGOAL podemos configurar el modelo facilmente pues solo necesitamos instanciar la clase AutomML. Lo más importante es elegir los tipos adecuados para datos de entrada y salida en nuestro modelo y la métrica de evaluación. En este caso:\r\n",
        "\r\n",
        "- entrada (input): MatrixContinuousDense -> una fila por instancia y una columna por variable.\r\n",
        "\r\n",
        "- salida (output): CategoricalVector -> el elemento *i* representa la categoría asociada a la instancia *i*.\r\n",
        "\r\n",
        "Ejecute la siguiente casilla prestando atención a los comentarios adicionales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZoQNW4PClt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52ac2af-0d0b-417d-b186-61992fcd4d4c"
      },
      "source": [
        "# configuraciones\n",
        "cfg = {}\n",
        "cfg['iterations'] = 1 # cantidad de iteraciones a realizar\n",
        "cfg['popsize'] = 50  # tamaño de la población\n",
        "cfg['search_timeout'] = 3600  # tiempo máximo de búsqueda en segundos\n",
        "cfg['evaluation_timeout'] = 600  # tiempo máximo que empleará evaluando un pipeline en segundos\n",
        "cfg['memory'] = 20  # cantidad máxima de memoria a utilizar\n",
        "cfg['score_metric'] = f1_score  # métrica de evaluación\n",
        "\n",
        "classifier = AutoML(\n",
        "    input=MatrixContinuousDense(),  # tipo datos de entrada\n",
        "    output=CategoricalVector(),  # tipo datos de salida\n",
        "    \n",
        "    score_metric=cfg['score_metric'],\n",
        "    search_algorithm=PESearch,  # algoritmo de búsqueda\n",
        "    registry=None,  # para incluir clases adicionales\n",
        "    \n",
        "    search_kwargs=dict(\n",
        "        pop_size=cfg['popsize'],\n",
        "        search_timeout=cfg['search_timeout'],\n",
        "        evaluation_timeout=cfg['evaluation_timeout'],\n",
        "        memory_limit=cfg['memory'] * 1024 ** 3,\n",
        "    ), \n",
        "    search_iterations=cfg['iterations'],\n",
        "    \n",
        "    include_filter=\".*\",  # indica qué módulos pueden incluirse en los pipelines evaluados\n",
        "    exclude_filter=None,  # indica módulos a excluir de los pipelines evaluados\n",
        "    \n",
        "    validation_split=0.3,  # porción de los datos de entrenamiento que AutoGOAL tomará para evaluar cada pipeline\n",
        "    cross_validation_steps=3,  # cantidad de particiones en la crossvalidación\n",
        "    cross_validation=\"mean\",  # tipo de agregación para los valores de la métrica en cada partición de la crossvalidación (promedio, mediana, etc.)\n",
        "    \n",
        "    random_state=None,  # semilla para el generador de números aleatorios\n",
        "    errors=\"warn\",  # tratamiento ante errores\n",
        "    metalearning_log=False,  # logs adicionales de la librería AutoGOAL\n",
        ")\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRRPI2CzOCOo"
      },
      "source": [
        "### Pre-procesamiento de los datos\r\n",
        "\r\n",
        "Antes de entrenar, debemos pre-procesar los datos. Esto dependerá de la tarea en particular, en este caso, comprende:\r\n",
        "\r\n",
        "- obtener vectores tf-idf correspondientes a cada ejemplo.\r\n",
        "\r\n",
        "**Notar que:**\r\n",
        "\r\n",
        "- en dependencia de su implementación del extractor, deberá re-implementar esta sección.\r\n",
        "\r\n",
        "Ejecute la siguiente casilla prestando atención a los comentarios explicativos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yoryqRsO8ik"
      },
      "source": [
        "#### Instanciar tf-idf vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNb1SPTMClt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82524f74-2940-4880-ed94-4525228765ad"
      },
      "source": [
        "# instanciar TfidfVectorizer\n",
        "cfg['vectorizer'] = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuOwIoYjPLC8"
      },
      "source": [
        "#### Pre-procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nlsy-9IClt-",
        "outputId": "8bcd1cdb-1e8d-47ad-bcf3-61a1d4d4954c"
      },
      "source": [
        "# entrenar TfidfVectorizer\r\n",
        "cfg['vectorizer'].fit(train[text_col].to_list())\r\n",
        "\r\n",
        "# guardar TfidfVectorizer entrenado para su posterior uso (codificar nuevos datos).\r\n",
        "with open('vectorizer_reviews.pkl', 'wb') as f:\r\n",
        "    pickle.dump(cfg['vectorizer'], f)\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rn4Poq2R4UX"
      },
      "source": [
        "### Entrenamiento del modelo\r\n",
        "\r\n",
        "Por último es necesario \"entrenar el modelo\", que en este caso significa iniciar la búsqueda.\r\n",
        "\r\n",
        "classifier.fit(X_train, y_train, logger=loggers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2Rf7dvXh7m"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}
>>>>>>> 469f22c8719ffa234e975d9f6570956716d80059
