{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01-SA-Pipeline-Reviews.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NSF0oGu78Tcx"},"source":["\n","# Entrenamiento y ejecución de un pipeline de clasificación textual\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo crear un pipeline para la clasificación de textos, entrenarlo y utilizarlo para clasificar nuevos datos.\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- algunos tipos de carácterísticas ampliamente utilizadas en la clasificación de textos. \n","- cómo contruir un pipeline para la clasificación de textos utilizando sklearn.\n","- utilizar este pipeline para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6 - 3.8\n","- pandas\n","- plotly\n"]},{"cell_type":"markdown","metadata":{"id":"AwN4Y_Rr8waB"},"source":["## Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciónes dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"aRnmup7KQC5G"},"source":["#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","\n","# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","\n","# para pre-procesamiento del texto y extraer carácterísticas\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from nltk.stem.snowball import EnglishStemmer\n","\n","# algorítmos de clasificación\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","\n","# para construir pipelines\n","from sklearn.pipeline import Pipeline\n","\n","# para evaluar los modelos \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score  \n","\n","# para guardar el modelo\n","import pickle\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RZOXOCU9WXq"},"source":["## Definición de funciones y variables necesarias para el preprocesamiento de datos\n","\n","Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."]},{"cell_type":"code","metadata":{"id":"Jbiz7i6FPFfP"},"source":["\n","#listado de stopwords. Este listado también se puede leer desde un fichero utilizando la función read_corpus\n","stop_words=['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves',\n","            'he','him','his','himself','she','her','hers','herself','it','its','itself','they','them','their',\n","            'theirs','themselves','what','which','who','whom','this','that','these','those','am','is','are',\n","            'was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an',\n","            'the','and','but','if','or','because','as','until','while','of','at','by','for','with','about',\n","            'against','between','into','through','during','before','after','above','below','to','from','up',\n","            'down','in','out','on','off','over','under','again','further','then','once','here','there','when',\n","            'where','why','how','all','any','both','each','few','more','most','other','some','such','no','nor',\n","            'not','only','own','same','so','than','too','very','s','t','can','will','just','don','should','now', 'ever']\n","\n","\n","# obtiene un dataframe de pandas\n","def read_corpus(file, sep):\n","    return pd.read_csv(file, sep)\n","\n","\n","# muestra gráficamente la distribución de clases del conjunto de datos utilizado\n","def plot(corpus):\n","    dist = corpus.groupby([\"Sentiment\"]).size()\n","    dist = dist / dist.sum()* 100\n","    fig, ax = plt.subplots(figsize=(12, 8))\n","    sns.barplot(dist.keys(), dist.values);\n","    plt.show()\n","\n","\n","# función auxiliar utilizada por CountVectorizer para procesar las frases\n","def english_stemmer(sentence):\n","    stemmer = EnglishStemmer()\n","    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=stop_words,\n","                               ngram_range=(1, 1)).build_analyzer()\n","    return (stemmer.stem(word) for word in analyzer(sentence))\n","\n","\n","# entrena el pipeline\n","def fit_model(data, target, pipeline):\n","    pipeline.fit(data, target)\n","\n","\n","# utiliza el pipeline para predecir datos\n","def predict(data_test, pipeline):\n","    return pipeline.predict(data_test)\n","\n","\n","# evalua el pipeline entrenado de acuerdo a una de las métricas apropiadas para un problema de clasificación. \n","def evaluate_model(predicted, target_test):\n","    print(classification_report(target_test, predicted))\n","    print(\"The accuracy score is {:.2%}\".format(accuracy_score(target_test, predicted)))\n","\n","\n","# guarda un pipeline entrenado\n","def saveModel(model, modelName = \"pickle_model.pkl\"):\n","   pkl_filename = modelName\n","   with open(pkl_filename, 'wb') as file:\n","    pickle.dump(model, file)   \n","\n","\n","# carga un pipeline entrenado y guardado previamente\n","def loadModel(rutaModelo = \"pickle_model.pkl\"):\n","  # Load from file\n","  with open(rutaModelo, 'rb') as file:\n","    pickle_model = pickle.load(file)\n","    return pickle_model "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYXr8ivvucB6"},"source":["## Creación de un pipeline para la clasificación de textos.\n","\n","Para construir el pipeline, utilizaremos la clase Pipeline de sklean. Esta permite encadenar los diferentes pasos, por ejemplo, algoritmos de extracción de características y un clasificador. Por ejemplo, para obtener un pipeline que comprende CountVectorizer, seguido de TfidfTransformer y un Support Vector Machine como clasificador, se utilizaría esta sentencia:\n","\n","~~~ \n","Pipeline([\n","        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n","        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n","        (classifier, SVC(probability=True) )\n","     ])\n","~~~\n","\n","Para tener mayor flexibilidad si se desean probar varios clasificadores, podría construirse el pipeline sin clasificador, incluyendo este con posterioridad. Este será el enfoque que seguiremos en la actividad.\n","\n","Ejecute la siguiente casilla para definir una función que construye un pipeline con las características antes mencionadas.\n"]},{"cell_type":"code","metadata":{"id":"Ei1DHRhRucYZ"},"source":["def preprocessPipeLine():\n","    return Pipeline([\n","        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n","        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n","     ])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UdRBoUg9tU9"},"source":["## Carga de datos y análisis exploratorio.\n","\n","Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\n","\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\n","\n","- leer los datos desde un fichero en una carpeta local.\n","\n","- leer los datos directamente de un URL.\n","\n","Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\n"]},{"cell_type":"code","metadata":{"id":"ZrxBtAfXUPPc"},"source":["# descomente las siguientes 2 líneas para leer datos desde Google Drive,sumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","corpus = pd.read_csv('/content/drive/MyDrive/Datos/review.csv', sep=',')\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#corpus = pd.read_csv('/sample_data/review.csv', sep=',')\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","#corpus = pd.read_csv('/content/sample_data/review.csv')\n","\n","\n","# graficar distribución de clases en los datos\n","colors = ['darkgreen', 'red']\n","categories = sorted(corpus['Sentiment'].unique())\n","hist= Counter(corpus['Sentiment'])\n","\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())], marker_color=colors))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bozyrzk8-UCH"},"source":["## Definición de una función para el entrenamiento del modelo\n","\n","Ejecute la siguiente casilla para definir la función *main*  que integra todas las funciones definidas para constuir el pipeline, entrenarlo, evaluarlo y guardarlo para su posterior uso.\n"]},{"cell_type":"code","metadata":{"id":"E5Sp_8RVTLqA"},"source":["def main():  \n","    \n","    # crear el pipeline (solo incluyendo los pasos de pre-procesamiento)\n","    pipeline=preprocessPipeLine()\n","    \n","    # crear el clasificador y añadirlo al pipeline. Puede probar diferentes clasificadores\n","    # classifier = MultinomialNB()\n","    # classifier = DecisionTreeClassifier()\n","    classifier = SVC(probability=True)\n","\n","    pipeline.steps.append(('classifier', classifier))\n","\n","    # preparar conjuntos de entrenamiento (60%) y prueba (40%)\n","    data_train, data_test, target_train, target_test = train_test_split(corpus['Phrase'].values, corpus['Sentiment'].values, test_size=0.4, random_state=43)\n","\n","    # entrenar el modelo\n","    fit_model(data_train, target_train, pipeline)\n","\n","    # predecir y evaluar el modelo en el conjunto de entrenamiento\n","    print('=== Evaluación conjunto de entrenamiento ====')\n","    predicted = predict(data_train, pipeline)\n","    evaluate_model(predicted, target_train)\n","\n","    # predecir y evaluar el modelo en el conjunto de prueba\n","    print('\\n=== Evaluación conjunto de entrenamiento ====')\n","    predicted = predict(data_test, pipeline)\n","    evaluate_model(predicted, target_test)\n","\n","    # guardar el modelo\n","    saveModel(pipeline)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzMUiKT28Rrs"},"source":["Finalmente, llamamos a la función *main* para entrenar el pipeline, evaluarlo y guardarlo."]},{"cell_type":"code","metadata":{"id":"E0bKIO23TmuW"},"source":["main()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EKPISmflTW3b"},"source":["# Predicción de nuevos datos\n","\n","Una vez que disponemos de un pipeline entrenado y guardado, podemos cargarlo para predecir nuevos datos.\n","\n","Ejecute la siguiente casilla prestando atención a las explicaciones dadas en los comentarios."]},{"cell_type":"code","metadata":{"id":"E0pEVuSzQNbI"},"source":["# datos a predecir. Notar que estos podrian obtenerse desde un fichero de modo similar a como se cargaron los datos de entrenamiento.\n","# Notar que para predecir nuevos datos no es necesario conocer su clasificación, !para esto utilizaremos el pipeline entrenado!\n","Xtest = [\"The movie was awesome!\",\"Martin Campbell has produced better novels.\",\"I liked the views but the rest of the movie was awful.\"]\n","\n","# cargar pipeline entrenado\n","pickle_model = loadModel()\n","\n","# predecir los nuevos datos\n","print(pickle_model.predict(Xtest))\n","\n","# predecir los nuevos datos, mostrando la probabilidad de la clasificación\n","print(pickle_model.predict_proba(Xtest))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkLCCX-7QBU6"},"source":[""]},{"cell_type":"code","metadata":{"id":"U3sKmB36s5ma"},"source":[""],"execution_count":null,"outputs":[]}]}