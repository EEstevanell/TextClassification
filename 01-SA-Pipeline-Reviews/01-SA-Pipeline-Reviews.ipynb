{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-SA-Pipeline-Reviews.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeachingTextMining/TextClassification/blob/main/01-SA-Pipeline-Reviews/01-SA-Pipeline-Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSF0oGu78Tcx"
      },
      "source": [
        "## Entrenamiento y ejecución de un pipeline de clasificación textual.\n",
        "\n",
        "La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n",
        "\n",
        "- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n",
        "- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n",
        "\n",
        "En la actividad exploraremos cómo crear un pipeline y entrenarlo para clasificar reviews de [IMDB]() sobre películas en las categorías \\[$positive$, $negative$\\]\n",
        "\n",
        "Puede encontrar más información sobre este problema en [Kaggle](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) y en [Large Movie Review Datase](http://ai.stanford.edu/~amaas/data/sentiment/). \n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "- siga las indicaciones y comentarios en cada apartado.\n",
        "\n",
        "**Después de esta actividad nos habremos familiarizado con:**\n",
        "- algunos tipos de carácterísticas ampliamente utilizadas en la clasificación de textos. \n",
        "- cómo contruir un pipeline para la clasificación de textos utilizando sklearn.\n",
        "- utilizar este pipeline para clasificar nuevos textos.\n",
        "\n",
        "**Requerimientos**\n",
        "- python 3.6 - 3.8\n",
        "- pandas\n",
        "- plotly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwN4Y_Rr8waB"
      },
      "source": [
        "### Instalación de librerías e importación de dependencias.\n",
        "\n",
        "Para comenzar, es preciso instalar e incluir las librerías necesarias. En este caso, el entorno de Colab incluye las necesarias.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a las explicaciónes dadas en los comentarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRnmup7KQC5G"
      },
      "source": [
        "#  para construir gráficas y realizar análisis exploratorio de los datos\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# para cargar datos y realizar pre-procesamiento básico\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# para pre-procesamiento del texto y extraer carácterísticas\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "\n",
        "# algoritmos de clasificación\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# para construir pipelines\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# para evaluar los modelos \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, plot_roc_curve\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# para guardar el modelo\n",
        "import pickle\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RZOXOCU9WXq"
      },
      "source": [
        "### Definición de funciones y variables necesarias para el preprocesamiento de datos\n",
        "\n",
        "Antes de definir el pipeline definiremos algunas variables útiles como el listado de stop words y funciones para cargar los datos, entrenar el modelo etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbiz7i6FPFfP"
      },
      "source": [
        "#listado de stopwords. Este listado también se puede leer desde un fichero utilizando la función read_corpus\n",
        "stop_words=['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself','yourselves',\n",
        "            'he','him','his','himself','she','her','hers','herself','it','its','itself','they','them','their',\n",
        "            'theirs','themselves','what','which','who','whom','this','that','these','those','am','is','are',\n",
        "            'was','were','be','been','being','have','has','had','having','do','does','did','doing','a','an',\n",
        "            'the','and','but','if','or','because','as','until','while','of','at','by','for','with','about',\n",
        "            'against','between','into','through','during','before','after','above','below','to','from','up',\n",
        "            'down','in','out','on','off','over','under','again','further','then','once','here','there','when',\n",
        "            'where','why','how','all','any','both','each','few','more','most','other','some','such','no','nor',\n",
        "            'not','only','own','same','so','than','too','very','s','t','can','will','just','don','should','now', 'ever']\n",
        "\n",
        "\n",
        "# obtiene un dataframe de pandas\n",
        "def read_corpus(file, sep):\n",
        "    return pd.read_csv(file, sep)\n",
        "\n",
        "\n",
        "# muestra gráficamente la distribución de clases del conjunto de datos utilizado\n",
        "def plot(corpus):\n",
        "    dist = corpus.groupby([\"Sentiment\"]).size()\n",
        "    dist = dist / dist.sum()* 100\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    sns.barplot(dist.keys(), dist.values);\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# función auxiliar utilizada por CountVectorizer para procesar las frases\n",
        "def english_stemmer(sentence):\n",
        "    stemmer = EnglishStemmer()\n",
        "    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=stop_words,\n",
        "                               ngram_range=(1, 1)).build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(sentence))\n",
        "\n",
        "\n",
        "# entrena el pipeline\n",
        "def fit_model(data, target, pipeline):\n",
        "    pipeline.fit(data, target)\n",
        "\n",
        "\n",
        "# utiliza el pipeline para predecir datos\n",
        "def predict(model, data):\n",
        "    return model.predict(data)\n",
        "\n",
        "\n",
        "# utiliza el pipeline para obtener la probabilidad de la predicción\n",
        "def predict_proba(model, data):\n",
        "    return model.predict_proba(data)\n",
        "\n",
        "\n",
        "# evalua el pipeline entrenado de acuerdo a una de las métricas apropiadas para un problema de clasificación\n",
        "def evaluate_model(model, X, y_true):\n",
        "    y_pred = predict(model, X)\n",
        "\n",
        "    print('==== Sumario de la clasificación ==== ')\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n",
        "    \n",
        "    if hasattr(model, 'predict_proba'):\n",
        "      y_scores = predict_proba(model, X)[:,1]\n",
        "      rocs = roc_auc_score(y_true, y_scores)\n",
        "      #rocc = roc_curve(y_true, y_score[:,1], pos_label='positive')\n",
        "\n",
        "      print('ROC Score ->  {:.2%}\\n'.format(rocs))\n",
        "      plot_roc_curve(model, X, y_true)\n",
        "      #print(rocc)\n",
        "\n",
        "    print('==== Matriz de confusión ==== ')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    display_labels = unique_labels(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=display_labels)\n",
        "    disp.plot(include_values=True)\n",
        "\n",
        "\n",
        "\n",
        "# guarda un pipeline entrenado\n",
        "def saveModel(model, modelName = \"pickle_model.pkl\"):\n",
        "   pkl_filename = modelName\n",
        "   with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)   \n",
        "\n",
        "\n",
        "# carga un pipeline entrenado y guardado previamente\n",
        "def loadModel(rutaModelo = \"pickle_model.pkl\"):\n",
        "  # Load from file\n",
        "  with open(rutaModelo, 'rb') as file:\n",
        "    pickle_model = pickle.load(file)\n",
        "    return pickle_model \n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYXr8ivvucB6"
      },
      "source": [
        "### Creación de un pipeline para la clasificación de textos.\n",
        "\n",
        "Para construir el pipeline, utilizaremos la clase Pipeline de sklean. Esta permite encadenar los diferentes pasos, por ejemplo, algoritmos de extracción de características y un clasificador. Por ejemplo, para obtener un pipeline que comprende CountVectorizer, seguido de TfidfTransformer y un Support Vector Machine como clasificador, se utilizaría esta sentencia:\n",
        "\n",
        "~~~ \n",
        "Pipeline([\n",
        "        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n",
        "        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n",
        "        (classifier, SVC(probability=True) )\n",
        "     ])\n",
        "~~~\n",
        "\n",
        "Para tener mayor flexibilidad si se desean probar varios clasificadores, podría construirse el pipeline sin clasificador, incluyendo este con posterioridad. Este será el enfoque que seguiremos en la actividad.\n",
        "\n",
        "Ejecute la siguiente casilla para definir una función que construye un pipeline con las características antes mencionadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei1DHRhRucYZ"
      },
      "source": [
        "def preprocessPipeLine():\n",
        "    return Pipeline([\n",
        "        ('dataVect', CountVectorizer(analyzer=english_stemmer)),\n",
        "        ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True)),\n",
        "     ])\n",
        "    \n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdRBoUg9tU9"
      },
      "source": [
        "### Carga de datos y análisis exploratorio.\n",
        "\n",
        "Antes de entrenar el pipeline, es necesario cargar los datos. Existen diferentes opciones, entre estas:\n",
        "\n",
        "- montar nuestra partición de Google Drive y leer un fichero desde esta.\n",
        "\n",
        "- leer los datos desde un fichero en una carpeta local.\n",
        "\n",
        "- leer los datos directamente de un URL.\n",
        "\n",
        "Ejecute la siguiente casilla prestando atención a las instrucciones adicionales en los comentarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrxBtAfXUPPc"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive,sumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline-Reviews/sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "\n",
        "# leer los datos\n",
        "data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he_d4nC4T1y4"
      },
      "source": [
        "Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YMzqSRUT150"
      },
      "source": [
        "# obtener algunas estadísticas sobre los datos\r\n",
        "categories = sorted(data['Sentiment'].unique(), reverse=True)\r\n",
        "hist= Counter(data['Sentiment']) \r\n",
        "print('Total de instancias -> {0}'.format(data.shape[0]))\r\n",
        "print('Distribución de clases -> {0}'.format({item[0]:round(item[1]/len(data['Sentiment']), 3) for item in sorted(hist.items(), key=lambda x: x[0])}))\r\n",
        "\r\n",
        "print('Categorías -> {0}'.format(categories))\r\n",
        "print('Comentario de ejemplo -> {0}'.format(data['Phrase'][0]))\r\n",
        "print('Categoría del comentario -> {0}'.format(data['Sentiment'][0]))\r\n",
        "\r\n",
        "colors = ['darkgreen', 'red']\r\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())], marker_color=colors))\r\n",
        "fig.show()\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bozyrzk8-UCH"
      },
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Ejecute la siguiente casilla  que integra todas las funciones definidas para constuir el pipeline, entrenarlo y guardarlo para su posterior uso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Sp_8RVTLqA"
      },
      "source": [
        "# crear el pipeline (solo incluyendo los pasos de pre-procesamiento)\n",
        "pipeline=preprocessPipeLine()\n",
        "\n",
        "# crear el clasificador y añadirlo al pipeline. Puede probar diferentes clasificadores\n",
        "# classifier = MultinomialNB()\n",
        "# classifier = DecisionTreeClassifier()\n",
        "classifier = SVC(probability=True)\n",
        "\n",
        "pipeline.steps.append(('classifier', classifier))\n",
        "\n",
        "\n",
        "# obtener conjuntos de entrenamiento (90%) y validación (10%)\n",
        "seed = 0    # fijar random_state para reproducibilidad\n",
        "train, val = train_test_split(data, test_size=.1, stratify=data['Sentiment'], random_state=seed)\n",
        "\n",
        "\n",
        "# entrenar el modelo\n",
        "fit_model(train['Phrase'], train['Sentiment'], pipeline)\n",
        "\n",
        "\n",
        "# guardar el modelo\n",
        "saveModel(pipeline)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMUiKT28Rrs"
      },
      "source": [
        "Luego de entranado el modelo, podemos evaluar su desempeño en los conjuntos de entramiento y validación.\r\n",
        "\r\n",
        "Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0bKIO23TmuW"
      },
      "source": [
        "# predecir y evaluar el modelo en el conjunto de entrenamiento\r\n",
        "print('==== Evaluación conjunto de entrenamiento ====')\r\n",
        "\r\n",
        "evaluate_model(model, train['Phrase'], train['Sentiment'])\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jv7xRTa0GaN"
      },
      "source": [
        "Ejecute la siguiente casilla para evaluar el modelo en el conjunto de validación. Compare los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9vNzF3D0GpU"
      },
      "source": [
        "# predecir y evaluar el modelo en el conjunto de entrenamiento\r\n",
        "print('==== Evaluación conjunto de validación ====')\r\n",
        "\r\n",
        "evaluate_model(model, val['Phrase'], val['Sentiment'])\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwu2I5DTBvGS"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "y = np.array([1, 1, 2, 2])\r\n",
        "scores = np.array([0.1, 0.4, 0.35, 0.8])\r\n",
        "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKPISmflTW3b"
      },
      "source": [
        "## Predicción de nuevos datos.\n",
        "\n",
        "Una vez entrenado el modelo, podemos evaluar su rendimiento en datos no utilizados durante el entrenamiento o emplearlo para predecir nuevas instancias. En cualquier caso, se debe cuidar realizar los pasos de pre-procesamiento necesarios según el caso. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n",
        "\n",
        "**Notar que**:\n",
        "-  se cargará el modelo previamente entrenado, estableciendo las configuraciones pertinentes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2mEFOG-ddAQ"
      },
      "source": [
        "### Instanciar modelo pre-entrenado\r\n",
        "\r\n",
        "Para predecir nuevas instancias es preciso cargar el modelo previamente entrenado. Esto dependerá del formato en el que se exportó el modelo, pero en general se requieren dos elementos: la estructura del modelo y los pesos. \r\n",
        "\r\n",
        "Ejecute la siguiente casilla para cargar el modelo entrenado previamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsUS0WEQddNQ"
      },
      "source": [
        "# cargar pipeline entrenado\r\n",
        "model = loadModel()\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQALJSVbdus2"
      },
      "source": [
        "### Predecir nuevos datos\r\n",
        "\r\n",
        "Con el modelo cargado, es posible utilizarlo para analizar nuevos datos. \r\n",
        "\r\n",
        "Ejecute las siguientes casillas para:\r\n",
        "\r\n",
        "(a) categorizar un texto de muestra.\r\n",
        "\r\n",
        "(b) cargar nuevos datos, categorizarlos y mostrar algunas estadísticas sobre el corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsWQHd2pdu03"
      },
      "source": [
        "# ejemplo de texto a clasificar\r\n",
        "text = ['Brian De Palma\\'s undeniable virtuosity can\\'t really camouflage the fact that his plot here is a thinly disguised\\\r\n",
        "        \\\"Psycho\\\" carbon copy, but he does provide a genuinely terrifying climax. His \"Blow Out\", made the next year, was an improvement.']\r\n",
        "\r\n",
        "\r\n",
        "# predecir los nuevos datos\r\n",
        "pred_labels = model.predict(text)\r\n",
        "pred_proba = model.predict_proba(text)\r\n",
        "print('La categoría del review es -> {0}'.format(pred_labels))\r\n",
        "print('La confidencia de la predicción es -> {0}'.format(pred_proba))\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj3Uokajeybr"
      },
      "source": [
        "También podemos predecir nuevos datos cargados desde un fichero. \r\n",
        "\r\n",
        "Ejecute la siguiente casilla, descomentando las instrucciones necesarias según sea el caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0pEVuSzQNbI"
      },
      "source": [
        "# descomente las siguientes 3 líneas para leer datos desde Google Drive,sumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n",
        "\n",
        "\n",
        "# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n",
        "#path = './sample_data/ejemplo_review_train.csv'\n",
        "\n",
        "\n",
        "# descomente la siguiente línea para leer datos desde un URL\n",
        "path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/01-SA-Pipeline-Reviews/sample_data/ejemplo_review_test.csv'\n",
        "\n",
        "\n",
        "# leer los datos\n",
        "new_data = pd.read_csv(path, sep=',')\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkLCCX-7QBU6"
      },
      "source": [
        "Ejecute la siguiente celda para predecir los datos y mostrar algunas estadísticas sobre el análisis realizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sKmB36s5ma"
      },
      "source": [
        "# predecir los datos de prueba\r\n",
        "pred_labels = model.predict(new_data['Phrase'])\r\n",
        "\r\n",
        "\r\n",
        "# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\r\n",
        "categories = ['positive', 'negative']\r\n",
        "hist = Counter(pred_labels) \r\n",
        "\r\n",
        "colors = ['darkgreen', 'red']\r\n",
        "fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n",
        "fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())], marker_color=colors))\r\n",
        "fig.show()\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ3Ox5C-1g3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}