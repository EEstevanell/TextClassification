{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"02_TextClassification_with_Transformers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"76GWp3TtCltu"},"source":["## Clasificación de textos utilizando Transformers\n","\n","La clasificación de textos consiste en, dado un texto, asignarle una entre varias categorías. Algunos ejemplos de esta tarea son:\n","\n","- dado un tweet, categorizar su connotación como positiva, negativa o neutra.\n","- dado un post de Facebook, clasificarlo como portador de un lenguaje ofensivo o no.  \n","\n","En la actividad exploraremos cómo utilizar soluciones *out of the box* para esta tarea incluidas en la librería [Transformers](https://huggingface.co/transformers/) y su aplicación para clasificar reviews de [IMDB]() sobre películas en las categorías \\[$positive$, $negative$\\]. \n","\n","Puede encontrar más información sobre este problema en [Kaggle](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) y en [Large Movie Review Datase](http://ai.stanford.edu/~amaas/data/sentiment/).\n","\n","**Instrucciones:**\n","\n","- siga las indicaciones y comentarios en cada apartado.\n","\n","\n","**Después de esta actividad nos habremos familiarizado con:**\n","- seleccionar e instanciar modelos pre-entrenados para realizar clasificación de textos.\n","- cómo instanciar un pipeline para la clasificación de textos utilizando la librería Transformers.\n","- utilizar este pipeline para clasificar nuevos textos.\n","\n","**Requerimientos**\n","- python 3.6.12 - 3.8\n","- tensorflow==2.3.0\n","- transformers==4.2.1\n","- pandas==1.1.5\n","- plotly==4.13.0\n","- tqdm==4.56.0\n","- scikit-learn==0.24.0"]},{"cell_type":"markdown","metadata":{"id":"qs8-IuHAWhw2"},"source":["### Instalación de librerías e importación de dependencias.\n","\n","Para comenzar, es preciso instalar las dependencias y realizar los imports necesarios.\n","\n","Ejecute las siguientes casillas prestando atención a las instrucciones adicionales en los comentarios."]},{"cell_type":"code","metadata":{"id":"Lxub5L7JWiIl"},"source":["# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n","# Note que existen otras dependencias como tensorflow==2.3.0, etc. que en este caso se encontrarían ya instaladas\n","%%capture\n","!pip install transformers==4.2.1\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga7lVYFMCltv"},"source":["# para cargar datos y realizar pre-procesamiento básico\n","import pandas as pd\n","from collections import Counter\n","\n","# para evaluar los modelos \n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.utils.multiclass import unique_labels\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","from tqdm import tqdm\n","\n","# algoritmos de clasificación, tokenizadores, etc.\n","from transformers import TextClassificationPipeline, DistilBertTokenizer, TFDistilBertForSequenceClassification, ModelCard\n","\n","from transformers.tokenization_utils import TruncationStrategy\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ByEBYoR3hqzw"},"source":["### Carga de datos y análisis exploratorio\r\n","\r\n","El primer paso consiste en obtener los datos relacionados con nuestra tarea dejándolos en el formato adecuado.  Existen diferentes opciones, entre estas:\r\n","\r\n","- montar nuestra partición de Google Drive y leer un fichero desde esta.\r\n","\r\n","- leer los datos desde un fichero en una carpeta local.\r\n","\r\n","- leer los datos directamente de un URL.\r\n","\r\n","En este caso, se encuentran en un fichero separado por comas con la siguiente estructura:\r\n","\r\n","| Phrase | Sentiment| \r\n","| ------ | ------ |\r\n","| This movie is really not all that bad...    | positive |\r\n","\r\n","\r\n","Ejecute la siguiente casilla para leer los datos.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"tTBmYxkBhunP"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive,sumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\r\n","#from google.colab import drive\r\n","#drive.mount('/content/drive')\r\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\r\n","\r\n","\r\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\r\n","#path = './sample_data/ejemplo_review_train.csv'\r\n","\r\n","\r\n","# descomente la siguiente línea para leer datos desde un URL\r\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/02-SA-Transformers-Basic/sample_data/ejemplo_review_train.csv'\r\n","\r\n","\r\n","# leer los datos\r\n","data = pd.read_csv(path, sep=',')\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BiZ1Tf4Dh6k3"},"source":["Una vez leídos los datos, ejecute la siguiente casilla para construir una gráfica que muestra la distribución de clases en el corpus.\r\n"]},{"cell_type":"code","metadata":{"id":"f1c5ZREAh7Y_"},"source":["# obtener algunas estadísticas sobre los datos\r\n","categories = sorted(data['Sentiment'].unique(), reverse=True)\r\n","hist= Counter(data['Sentiment']) \r\n","print('Total de instancias -> {0}'.format(data.shape[0]))\r\n","print('Distribución de clases -> {0}'.format({item[0]:round(item[1]/len(data['Sentiment']), 3) for item in sorted(hist.items(), key=lambda x: x[0])}))\r\n","\r\n","print('Categorías -> {0}'.format(categories))\r\n","print('Comentario de ejemplo -> {0}'.format(data['Phrase'][0]))\r\n","print('Categoría del comentario -> {0}'.format(data['Sentiment'][0]))\r\n","\r\n","colors = ['darkgreen', 'red']\r\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\r\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())], marker_color=colors))\r\n","fig.show()\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cA2HwMRClty"},"source":["### Carga del modelo pre-entrenado\n","La librería Transformers provee diferentes modelos listos para usar en la tarea de clasificación de textos. Una forma flexible de lograrlo consiste en:\n","\n","- seleccionar un modelo pre-entrenado adecuado para la tarea. Podemos examinar los modelos disponibles en [https://huggingface.co/models](https://huggingface.co/models). Estaremos utilizando el llamado [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) que permite clasificar un texto en idioma inglés de acuerdo con su connotación **positiva** o **negativa**.\n","\n","- instanciar el modelo y su correspondiente tokenizador.\n","\n","- crear un pipeline para la clasificación de textos, en este caso utilizando la clase [TextClassificationPipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextClassificationPipeline).\n","\n","- utilizar el pipeline para clasificar textos.\n","\n","\n","Ejecute la siguiente celda para instanciar el modelo y el correspondiente tokenizador.\n","\n","**Note que:**\n","- la práctica recomendada al crear un nuevo modelo para Transformers es hacerlo disponible mediante un fichero que contiene los elementos necesarios para su posterior uso, como son el modelo, el tokenizador y una tarjeta con metadatos sobre el modelo. \n","\n","- es conveniente indagar sobre el modelo base utilizado, en este caso **DistilBert**, esto permitirá seleccionar las clases adecuadas para instanciar el modelo.\n"]},{"cell_type":"code","metadata":{"id":"ozSej98kCltz"},"source":["# configuraciones\n","trained_model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n","max_length = 512    # máxima longitud de secuencia recomendada por DistilBERT\n","\n","# cargar el tokenizador, disponible en Transformers. Establecer model_max_length para cuando el tokenizador sea llamado, trunque automáticamente.\n","tokenizer = DistilBertTokenizer.from_pretrained(trained_model_name, model_max_length=max_length)\n","\n","# cargar el modelo, disponible en Transformers\n","model = TFDistilBertForSequenceClassification.from_pretrained(trained_model_name)\n","modelcard = ModelCard.from_pretrained(trained_model_name)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zquRgvcClt1"},"source":["Una vez instanciado el modelo y el tokenizador, instanciamos el pipeline de clasificación de textos. \n","\n","Ejecute la siguiente celda para crear una instancia de TextClassificationPipeline a partir del modelo y tokenizador."]},{"cell_type":"code","metadata":{"id":"cnLyQIT_Clt2"},"source":["classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer, modelcard=None, framework='tf', task='sentiment-analysis', return_all_scores=False)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qvWMQ9x4Clt4"},"source":["Ejecute la siguiente celda para clasificar una la frase. Alternativamente, puede modificar el texto incluyendo uno de su preferencia. Recuerde que debe ser en idioma inglés."]},{"cell_type":"code","metadata":{"id":"uZoQNW4PClt4"},"source":["text = \"Natural Language Processing is a very interesting subject.\"\n","output = classifier(text, truncation=TruncationStrategy.ONLY_FIRST)\n","print(output)\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sX_NrA0NY7oP"},"source":["### Evaluación del modelo\r\n","\r\n","En este caso no ha sido necesario entrenar el modelo, no obstante, lo evaluaremos en un conjunto reviews para los que se conoce su categoría de modo que podamos estimar el desempeño en nuevos datos.\r\n","\r\n","Ejecute la siguiente casilla para evaluar el modelo en el conjunto de entrenamiento.\r\n","\r\n","**Notar que:**\r\n","\r\n","- la salida del modelo es un diccionario con 'label' y 'score'. Debemos formatearla para poder comparar con los valores de referencia.\r\n","\r\n","- para evitar problemas relacionados con el consumo de memoria, se realizará la predicción de instancias por lotes. Además se utilizará TruncationStrategy.ONLY_FIRST para indicar al pipeline que trunque las secuencias con longitud mayor a la recomendada por el modelo."]},{"cell_type":"code","metadata":{"id":"ptboGvWxiRqN"},"source":["# configuraciones\r\n","batch_size = 128\r\n","size = data.shape[0]\r\n","\r\n","# predecir los datos de entrenamiento\r\n","pred_labels = []\r\n","for i in tqdm(range(0, size, batch_size)):\r\n","    batch_text = data['Phrase'][i:i+batch_size].to_list()\r\n","    batch_labels = classifier(batch_text, truncation=TruncationStrategy.ONLY_FIRST)\r\n","    batch_labels = [pred['label'].lower() for pred in batch_labels]\r\n","    pred_labels.extend(batch_labels)\r\n","\r\n","target_labels = data['Sentiment']\r\n","\r\n","print('==== Sumario de la clasificación ==== ')\r\n","print(classification_report(target_labels, pred_labels))\r\n","\r\n","print('Accuracy -> {:.2%}'.format(accuracy_score(target_labels, pred_labels)))\r\n","\r\n","print('==== Matriz de confusión ==== ')\r\n","cm = confusion_matrix(target_labels, pred_labels)\r\n","display_labels = unique_labels(target_labels, pred_labels)\r\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=display_labels)\r\n","disp.plot(include_values=True)\r\n","\r\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj3fedYRClt6"},"source":["### Predicción de nuevos datos\n","Una vez evaluado el modelo para estimar su rendimiento en nuestro problema, podemos utilizarlo para predecir nuevos datos. En el ejemplo, utilizaremos la porción de prueba preparada inicialmente.\n","\n","Ejecute la siguiente casilla para cargar los datos, descomentando las instrucciones necesarias según sea el caso."]},{"cell_type":"code","metadata":{"id":"iNb1SPTMClt7"},"source":["# descomente las siguientes 3 líneas para leer datos desde Google Drive,sumiendo que se trata de un fichero llamado review.csv localizado dentro de una carpeta llamada 'Datos' en su Google Drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","#path = '/content/drive/MyDrive/Datos/ejemplo_review_train.csv'\n","\n","\n","# descomente la siguiente línea para leer los datos desde un archivo local, por ejemplo, asumiendo que se encuentra dentro de un directorio llamado sample_data\n","#path = './sample_data/ejemplo_review_train.csv'\n","\n","\n","# descomente la siguiente línea para leer datos desde un URL\n","path = 'https://github.com/TeachingTextMining/TextClassification/raw/main/02-SA-Transformers-Basic/sample_data/ejemplo_review_test.csv'\n","\n","\n","# leer los datos\n","new_data = pd.read_csv(path, sep=',')\n","\n","print('Done!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PZTb-wbUClt9"},"source":["Ejecute la siguiente celda para clasificar los textos. Tenga en cuenta que, en dependencia del entorno de ejecución, la cantidad de textos y su longitud, la ejecución puede tardar varios minutos o requerir una cantidad de memoria no disponible."]},{"cell_type":"code","metadata":{"id":"4nlsy-9IClt-"},"source":["# configuraciones\n","batch_size = 128\n","size = new_data.shape[0]\n","\n","# predecir los datos de entrenamiento\n","pred_labels = []\n","for i in tqdm(range(0, size, batch_size)):\n","    batch_text = new_data['Phrase'][i:i+batch_size].to_list()\n","    batch_labels = classifier(batch_text, truncation=TruncationStrategy.ONLY_FIRST)\n","    batch_labels = [pred['label'].lower() for pred in batch_labels]\n","    pred_labels.extend(batch_labels)\n","\n","\n","# obtener algunas estadísticas sobre la predicción en el conjunto de pruebas\n","categories = ['positive', 'negative']\n","hist = Counter(pred_labels) \n","\n","colors = ['darkgreen', 'red']\n","fig = go.Figure(layout=go.Layout(height=400, width=600))\n","fig.add_trace(go.Bar(x=categories, y=[hist[cat] for cat in sorted(hist.keys())], marker_color=colors))\n","fig.show()\n","\n","print('Done!')"],"execution_count":null,"outputs":[]}]}